{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "\n",
    "from models import StateAutoEncoder\n",
    "from environments import StateEncoder\n",
    "from train_sae import generate_dataset\n",
    "from utils import Normalizer\n",
    "from train_options import collect_data, compute_avg_reward, get_prepare\n",
    "from models import OptionHierachy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.getcwd()\n",
    "model_save_dir = dir_path+\"/saved/sae\"\n",
    "checkpoint_path = dir_path+\"/checkpoints/sae/\"\n",
    "n_epochs = 100\n",
    "steps_per_epoch = 10000\n",
    "batch_size = 64\n",
    "normalizer = Normalizer(0, 499)\n",
    "env_name = 'Taxi-v3'\n",
    "\n",
    "# dataset = generate_dataset(env_name, 200, normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = dataset.shard(num_shards=2, index=0).shuffle(buffer_size=1024).repeat().batch(\n",
    "#         batch_size, drop_remainder=True)\n",
    "# eval_dataset = dataset.shard(num_shards=2, index=1).shuffle(buffer_size=1024).repeat().batch(\n",
    "#         batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring from c:\\Projects\\LHLSA thesis/checkpoints/sae/ckpt\n"
     ]
    }
   ],
   "source": [
    "state_autoencoder = StateAutoEncoder(n_epochs, steps_per_epoch, 12, normalize=True, normalizer=normalizer)\n",
    "state_autoencoder.use_checkpoints(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      " [1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.\n",
      "  1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      " [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]]\n",
      "tf.Tensor(\n",
      "[[ 91.75054]\n",
      " [177.45905]\n",
      " [284.52228]\n",
      " [488.73895]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoding = state_autoencoder.encode([[100], [200], [301], [499]])\n",
    "print(encoding)\n",
    "decoding = state_autoencoder.decode(encoding)\n",
    "print(decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_autoencoder.compile()\n",
    "# history = state_autoencoder.fit(train_dataset)\n",
    "# state_autoencoder.save(args.savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000  # @param {type:\"integer\"}\n",
    "initial_collect_steps = 1000  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = StateEncoder(train_py_env, state_autoencoder)\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_env.time_step_spec())\n",
    "# print(train_env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eunov\\miniconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\autograph\\operators\\control_flow.py:1004: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "options_agent = OptionHierachy(\n",
    "    batch_size,\n",
    "    train_env.action_spec(),\n",
    "    train_env.time_step_spec(),\n",
    "    num_iterations,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "replay_buffer = options_agent.get_replay_buffer(\n",
    "    replay_buffer_max_length\n",
    ")\n",
    "\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2\n",
    ")\n",
    "iterator = iter(dataset)\n",
    "\n",
    "prepare = get_prepare(train_env.time_step_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_reward = compute_avg_reward(\n",
    "    eval_env, options_agent, num_eval_episodes)\n",
    "print(avg_reward)\n",
    "avg_reward_history = [avg_reward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data(\n",
    "    train_env, options_agent, replay_buffer,\n",
    "    initial_collect_steps, prepare=prepare\n",
    ")\n",
    "\n",
    "iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
